import marimo

__generated_with = "0.10.9"
app = marimo.App()


@app.cell
def __():
    import marimo as mo
    import pandas as pd
    import numpy as np
    import psycopg2
    import plotly.express as px
    import plotly.graph_objects as go
    from plotly.subplots import make_subplots
    from sklearn.decomposition import PCA
    from sklearn.manifold import TSNE
    from sklearn.metrics.pairwise import cosine_similarity
    import os
    from dotenv import load_dotenv
    
    load_dotenv()
    return (
        TSNE,
        PCA,
        cosine_similarity,
        go,
        load_dotenv,
        make_subplots,
        mo,
        np,
        os,
        pd,
        plotly,
        psycopg2,
        px,
    )


@app.cell
def __(mo):
    mo.md("""
    # üìñ Interactive Bible Embeddings Analysis
    
    **Goal**: Explore how Bible books relate to each other through semantic embeddings
    
    ### üéØ **Analysis Objectives**
    - **üìö Book Relationships**: Which books are most semantically similar?
    - **üîç OT vs NT Analysis**: How distinct are the testaments in embedding space?
    - **üîÑ Convergence Points**: Where do OT and NT themes overlap?
    - **üìä Similarity Patterns**: Discover thematic clusters and literary connections
    
    ### üìà **Interactive Features**
    - **Real-time visualization** with multiple dimensionality reduction methods
    - **Dynamic book selection** for similarity analysis
    - **Cross-testament convergence** rankings
    - **Quantitative separation metrics** with interpretation
    
    **Data Source**: Neon PostgreSQL Database (single source of truth)
    
    ---
    """)
    return


@app.cell
def __(mo, os, pd, psycopg2):
    # Load data from database
    def load_bible_data():
        database_url = os.getenv('DATABASE_URL')
        if not database_url:
            return None, None
        
        with psycopg2.connect(database_url, sslmode='require') as conn:
            # Load book chunks
            book_query = """
                SELECT id, book, testament, chunk_type, is_split, original_book, 
                       chapter_count, verse_count, embedding
                FROM book_chunks
                ORDER BY book, id
            """
            
            # Load chapter chunks  
            chapter_query = """
                SELECT id, book, testament, chapter, verse_count, embedding
                FROM chapter_chunks
                ORDER BY book, chapter
            """
            
            book_df = pd.read_sql_query(book_query, conn)
            chapter_df = pd.read_sql_query(chapter_query, conn)
        
        return book_df, chapter_df
    
    book_df, chapter_df = load_bible_data()
    
    if book_df is not None:
        mo.md(f"""
        ## ‚úÖ **Data Loaded Successfully**
        
        ### üìä **Dataset Overview**
        - **üìñ Book chunks**: {len(book_df):,}
        - **üìö Chapter chunks**: {len(chapter_df):,}
        - **üîó Testament distribution**: {book_df['testament'].value_counts().to_dict()}
        
        ### üéØ **Ready for Analysis**
        All data has been loaded from the Neon database and is ready for interactive exploration.
        """)
    else:
        mo.md("""
        ## ‚ùå **Error Loading Data**
        
        Could not load data from the database. Please check:
        - **DATABASE_URL** environment variable is set correctly
        - **Database connection** is active and accessible
        - **Tables exist** (`book_chunks`, `chapter_chunks`)
        
        Run `python bible_embeddings.py` first to populate the database.
        """)
    return book_df, chapter_df, load_bible_data


@app.cell
def __(book_df, np):
    # Prepare embeddings
    def prepare_embeddings(df, embedding_col='embedding'):
        embeddings = []
        for emb_str in df[embedding_col]:
            if emb_str:
                emb_str = emb_str.strip('[]')
                emb_array = np.array([float(x.strip()) for x in emb_str.split(',')])
                embeddings.append(emb_array)
            else:
                embeddings.append(np.zeros(768))
        return np.array(embeddings)
    
    book_embeddings = prepare_embeddings(book_df) if book_df is not None else None
    return book_embeddings, prepare_embeddings


@app.cell
def __(book_df, book_embeddings, np, pd):
    # Aggregate books into canonical 66 books
    def aggregate_books(book_df, book_embeddings):
        aggregated_books = []
        aggregated_embeddings = []
        
        # Get unique books
        all_books = set()
        for _, row in book_df.iterrows():
            if row['is_split']:
                all_books.add(row['original_book'])
            else:
                all_books.add(row['book'])
        
        for book_name in sorted(all_books):
            # Get all chunks for this book
            book_chunks = book_df[
                ((book_df['book'] == book_name) & (~book_df['is_split'])) |
                (book_df['original_book'] == book_name)
            ]
            
            if len(book_chunks) == 0:
                continue
            
            # Get embeddings for this book
            chunk_indices = book_chunks.index
            book_chunk_embeddings = book_embeddings[chunk_indices]
            
            # Aggregate using mean
            mean_embedding = np.mean(book_chunk_embeddings, axis=0)
            
            # Get metadata
            first_chunk = book_chunks.iloc[0]
            testament = first_chunk['testament']
            total_verses = book_chunks['verse_count'].sum()
            
            aggregated_books.append({
                'book': book_name,
                'testament': testament,
                'verse_count': total_verses,
                'chunk_count': len(book_chunks)
            })
            aggregated_embeddings.append(mean_embedding)
        
        return pd.DataFrame(aggregated_books), np.array(aggregated_embeddings)
    
    if book_df is not None and book_embeddings is not None:
        aggregated_df, aggregated_embeddings = aggregate_books(book_df, book_embeddings)
    else:
        aggregated_df, aggregated_embeddings = None, None
    return aggregate_books, aggregated_df, aggregated_embeddings


@app.cell
def __(aggregated_df, mo):
    if aggregated_df is not None:
        mo.md(f"""
        ## üìä **Canonical Bible Books Aggregated**
        
        ### üìñ **Book Distribution**
        - **Total Books**: {len(aggregated_df)} canonical books
        - **Old Testament**: {len(aggregated_df[aggregated_df['testament'] == 'OT'])} books
        - **New Testament**: {len(aggregated_df[aggregated_df['testament'] == 'NT'])} books
        
        ### üéØ **Ready for Analysis**
        Books have been aggregated from individual chunks into canonical 66-book representation for analysis.
        """)
    return


@app.cell
def __(mo):
    # Interactive controls
    mo.md("""
    ## üéõÔ∏è **Interactive Controls**
    
    Use the dropdown menus below to customize your analysis:
    
    ### üìä **Analysis Type**
    Choose what type of analysis to perform:
    - **Testament Separation**: Visualize OT vs NT clustering
    - **Book Similarities**: Find most similar books to a selected book
    - **Cross-Testament Convergence**: Discover OT-NT thematic bridges
    
    ### üìà **Visualization Method**
    Select dimensionality reduction technique:
    - **PCA**: Principal Component Analysis (linear, preserves variance)
    - **t-SNE**: t-Distributed Stochastic Neighbor Embedding (non-linear, preserves local structure)
    """)
    return


@app.cell
def __(aggregated_df, mo):
    # Book selection
    if aggregated_df is not None:
        book_options = sorted(aggregated_df['book'].tolist())
        selected_book = mo.ui.dropdown(
            options=book_options,
            value="Genesis",
            label="Select a book to analyze:"
        )
        selected_book
    else:
        selected_book = None
    return book_options, selected_book


@app.cell
def __(mo):
    # Analysis type selection
    analysis_type = mo.ui.radio(
        options=["Testament Separation", "Book Similarities", "Cross-Testament Convergence"],
        value="Testament Separation",
        label="Choose analysis type:"
    )
    analysis_type
    return analysis_type,


@app.cell
def __(mo):
    # Visualization method
    viz_method = mo.ui.radio(
        options=["PCA", "t-SNE"],
        value="PCA", 
        label="Dimensionality reduction method:"
    )
    viz_method
    return viz_method,


@app.cell
def __(PCA, TSNE, aggregated_embeddings, viz_method):
    # Apply dimensionality reduction based on selection
    if aggregated_embeddings is not None:
        if viz_method.value == "PCA":
            reducer = PCA(n_components=2, random_state=42)
            coords_2d = reducer.fit_transform(aggregated_embeddings)
            variance_explained = f"PC1: {reducer.explained_variance_ratio_[0]:.1%}, PC2: {reducer.explained_variance_ratio_[1]:.1%}"
        else:  # t-SNE
            reducer = TSNE(n_components=2, random_state=42, perplexity=min(30, len(aggregated_embeddings)-1))
            coords_2d = reducer.fit_transform(aggregated_embeddings)
            variance_explained = "t-SNE (non-linear embedding)"
    else:
        coords_2d = None
        variance_explained = ""
    return coords_2d, reducer, variance_explained


@app.cell
def __(aggregated_df, analysis_type, coords_2d, mo, px, variance_explained):
    # Create main visualization
    if coords_2d is not None and analysis_type.value == "Testament Separation":
        # Add coordinates to dataframe
        plot_df = aggregated_df.copy()
        plot_df['x'] = coords_2d[:, 0]
        plot_df['y'] = coords_2d[:, 1]
        
        # Create interactive plot
        fig = px.scatter(
            plot_df, 
            x='x', y='y',
            color='testament',
            hover_data=['book', 'verse_count'],
            text='book',
            title=f"Bible Books: Old Testament vs New Testament ({variance_explained})",
            color_discrete_map={'OT': 'blue', 'NT': 'orange'},
            width=900, height=700
        )
        
        fig.update_traces(textposition="top center", textfont_size=10)
        fig.update_layout(
            xaxis_title="Component 1",
            yaxis_title="Component 2",
            showlegend=True
        )
        
        mo.ui.plotly(fig)
    else:
        mo.md("Select 'Testament Separation' to see the visualization")
    return fig, plot_df


@app.cell
def __(aggregated_df, aggregated_embeddings, analysis_type, cosine_similarity, mo):
    # Book similarity analysis
    if analysis_type.value == "Book Similarities" and aggregated_df is not None:
        def analyze_book_similarities(target_book, top_k=10):
            if target_book not in aggregated_df['book'].values:
                return None
                
            target_idx = aggregated_df[aggregated_df['book'] == target_book].index[0]
            target_embedding = aggregated_embeddings[target_idx:target_idx+1]
            
            # Calculate similarities to all books
            similarities = cosine_similarity(target_embedding, aggregated_embeddings)[0]
            
            # Get top similar books (excluding self)
            similar_indices = np.argsort(similarities)[::-1][1:top_k+1]
            
            similar_books = []
            for idx in similar_indices:
                book = aggregated_df.iloc[idx]['book']
                testament = aggregated_df.iloc[idx]['testament']
                similarity = similarities[idx]
                similar_books.append({
                    'Book': book,
                    'Testament': testament, 
                    'Similarity': f"{similarity:.3f}"
                })
            
            return similar_books
        
        # Show analysis for selected book
        if hasattr(selected_book, 'value') and selected_book.value:
            similar_books = analyze_book_similarities(selected_book.value)
            if similar_books:
                similar_df = pd.DataFrame(similar_books)
                mo.md(f"## üìñ Books Most Similar to **{selected_book.value}**")
                mo.ui.table(similar_df)
            else:
                mo.md(f"Book '{selected_book.value}' not found")
        else:
            mo.md("Select a book above to see similarities")
    else:
        mo.md("Select 'Book Similarities' to see this analysis")
    return analyze_book_similarities, similar_books, similar_df


@app.cell
def __(aggregated_df, aggregated_embeddings, analysis_type, cosine_similarity, mo, pd):
    # Cross-testament convergence analysis
    if analysis_type.value == "Cross-Testament Convergence" and aggregated_df is not None:
        ot_books = aggregated_df[aggregated_df['testament'] == 'OT']
        nt_books = aggregated_df[aggregated_df['testament'] == 'NT']
        
        ot_embeddings = aggregated_embeddings[aggregated_df['testament'] == 'OT']
        nt_embeddings = aggregated_embeddings[aggregated_df['testament'] == 'NT']
        
        # Calculate cross-testament similarities
        cross_similarities = cosine_similarity(ot_embeddings, nt_embeddings)
        
        # Find top similarities
        top_pairs = []
        for i in range(len(ot_books)):
            for j in range(len(nt_books)):
                similarity = cross_similarities[i, j]
                ot_book = ot_books.iloc[i]['book']
                nt_book = nt_books.iloc[j]['book']
                top_pairs.append({
                    'OT Book': ot_book,
                    'NT Book': nt_book,
                    'Similarity': f"{similarity:.3f}"
                })
        
        # Sort by similarity and take top 15
        top_pairs_df = pd.DataFrame(top_pairs)
        top_pairs_df['Similarity_float'] = top_pairs_df['Similarity'].astype(float)
        top_pairs_df = top_pairs_df.sort_values('Similarity_float', ascending=False).head(15)
        top_pairs_df = top_pairs_df.drop('Similarity_float', axis=1)
        
        mo.md("## üîÑ Cross-Testament Convergence")
        mo.md("Books that show the highest thematic similarity across testaments:")
        mo.ui.table(top_pairs_df)
    else:
        mo.md("Select 'Cross-Testament Convergence' to see this analysis")
    return (
        cross_similarities,
        nt_books,
        nt_embeddings,
        ot_books,
        ot_embeddings,
        top_pairs,
        top_pairs_df,
    )


@app.cell
def __(aggregated_df, aggregated_embeddings, cosine_similarity, mo, np):
    # Testament separation metrics
    if aggregated_df is not None:
        ot_embeddings_sep = aggregated_embeddings[aggregated_df['testament'] == 'OT']
        nt_embeddings_sep = aggregated_embeddings[aggregated_df['testament'] == 'NT']
        
        # Calculate centroids
        ot_centroid = np.mean(ot_embeddings_sep, axis=0)
        nt_centroid = np.mean(nt_embeddings_sep, axis=0)
        
        # Calculate similarities
        testament_similarity = cosine_similarity([ot_centroid], [nt_centroid])[0][0]
        
        # Within-testament similarities
        ot_similarities = cosine_similarity(ot_embeddings_sep)
        nt_similarities = cosine_similarity(nt_embeddings_sep)
        
        ot_upper = ot_similarities[np.triu_indices_from(ot_similarities, k=1)]
        nt_upper = nt_similarities[np.triu_indices_from(nt_similarities, k=1)]
        
        ot_avg_similarity = np.mean(ot_upper)
        nt_avg_similarity = np.mean(nt_upper)
        
        mo.md(f"""
        ## üìä **Testament Separation Analysis**
        
        ### üîç **Quantitative Metrics**
        - **OT ‚Üî NT similarity**: `{testament_similarity:.3f}`
        - **Average OT internal similarity**: `{ot_avg_similarity:.3f}`
        - **Average NT internal similarity**: `{nt_avg_similarity:.3f}`
        
        ### üìà **Interpretation**
        {"‚úÖ **Excellent Separation**: Old and New Testaments are more semantically distinct from each other than books within each testament. This suggests clear thematic boundaries between the testaments." if testament_similarity < min(ot_avg_similarity, nt_avg_similarity) else "‚ö†Ô∏è **Limited Separation**: Old and New Testaments show significant thematic overlap. This could indicate strong continuity in themes across testaments."}
        
        ### üéØ **Key Insight**
        {"The analysis reveals clear semantic boundaries between Old and New Testaments, suggesting distinct theological and literary characteristics." if testament_similarity < min(ot_avg_similarity, nt_avg_similarity) else "The analysis shows significant thematic continuity between Old and New Testaments, indicating strong theological connections."}
        """)
    return (
        nt_avg_similarity,
        nt_centroid,
        nt_embeddings_sep,
        nt_similarities,
        nt_upper,
        ot_avg_similarity,
        ot_centroid,
        ot_embeddings_sep,
        ot_similarities,
        ot_upper,
        testament_similarity,
    )


@app.cell
def __(mo):
    mo.md("""
    ## üéØ Key Insights Summary
    
    This interactive analysis helps answer fundamental questions about biblical text relationships:
    
    ### üìö **Book Relationships**
    Use the book similarity analysis to explore which books share similar themes and language patterns. This reveals:
    - **Thematic clusters** within each testament
    - **Literary relationships** between books  
    - **Theological connections** across different genres
    
    ### üîç **Testament Distinction**
    The PCA/t-SNE visualization shows how well the Old and New Testaments cluster separately in semantic space, revealing:
    - **Semantic boundaries** between testaments
    - **Thematic continuity** or discontinuity
    - **Natural groupings** of related books
    
    ### üîÑ **Cross-Testament Convergence**
    Cross-testament analysis reveals where OT and NT books share the most thematic similarity, potentially indicating:
    - **Prophetic fulfillment patterns**
    - **Shared theological themes**
    - **Literary or stylistic connections**
    
    ---
    
    ## üîß Technical Details
    
    **Methodology:**
    - **Embedding Model**: Google text-embedding-004 (768 dimensions)
    - **Similarity Metric**: Cosine similarity (range: -1 to 1)
    - **Dimensionality Reduction**: PCA and t-SNE for visualization
    - **Data Source**: Neon PostgreSQL database (single source of truth)
    - **Book Coverage**: All 66 canonical books included
    
    **Interactive Features:**
    - **Real-time analysis** with dropdown selections
    - **Multiple visualization methods** (PCA, t-SNE)
    - **Detailed similarity matrices** and rankings
    - **Cross-testament convergence** analysis
    
    ---
    
    *This interactive analysis complements the comprehensive static reports in the `results/` directory.*
    """)
    return


if __name__ == "__main__":
    app.run() 